\section{Introduction}\label{intro}\sloppy
Recent advances in deep learning have enabled new forms of analytics on the content of images and videos. In the last two years, a number of systems have explored scaling visual analytics pipelines to larger and/or faster streams of data~\cite{anderson2018predicate, kang2018blazeit,kang2017noscope, wu2018querying, sparks2017keystoneml,haynes2018lightdb}. An archetypal task is to find all images in a corpus that contain a certain object, e.g., detecting people in CCTV footage. The proliferation of neural network-based object detection models (which identify and crop target objects from an image) have made such tasks feasible in the last few years~\cite{he2017mask}. Recent work has studied techniques for fast inference and aggregation on streams of predictions from object detection models~\cite{kang2018blazeit,kang2017noscope}.


However, the overarching problem of supporting queries on the content of videos and images is far from solved. Consider a variant of the task before: given two videos find a certain object that appears in both videos. For example, we might be interested in determining if the same person appeared in two different CCTV feeds. To answer this query, one has to first find potential target objects in both videos and then match them against each other. There are immediately implementation decisions about indexing (can one build an index for faster image matching), optimization (if we do index, which video to scan and what type of an index to use), and compression (can the matching be performed on low-dimensional features instead of raw frames).  These issues are analagous to physical design and physical operator selection in traditional relational database management systems, where a strong separation of logical and physical concerns enables a declarative user-facing interface and an extensible system-facing interface. The data and the query models used video analytics today lack an analagous separation, where the implementations of query operators are often tied to specific neural network familes, use cases, and data source semantics.



This paper explores the necessary components of a future Visual Data Management System (VDMS) in the era of Deep Learning, and what is needed to provide a truly declarative query language.
We built a research prototype system, called \textsf{DeepLens}, where visual analytics tasks are maps, joins, and filters over collections of subimages (called patches) and an associated key-value dictionary storing information them (e.g., labels or provenance). The query model in \textsf{DeepLens} has set semantics and makes no structural assumptions about the data source, e.g., any timing data in video are stored as additional attributes. Optimizations either for accuracy and performance are introduced through physical design, where \textsf{DeepLens} allows for the materialization, pre-computation, and both single-attribute and multi-dimensional indexing on patch collections.


This architecture disentangles the process that generates the patches with the downstream query processing of the collection--similar to the distinction between ETL and query processing.
We use this system to illustrate the impact of operator selection and physical design on a benchmark of six analytics tasks by varying what is indexed, how the operators are implemented, and the underlying hardware.
\textbf{Indexing: }We found that index usage was crucial and could query improve performance by up-to 612x. However, particularly for the geometric indices, the size and dimensionality of the data plays a key role in how beneficial an index will be.
\textbf{Lineage: }We found that many tasks require relating processed results back to the base data.
Maintaining and indexing tuple-level lineage led to a 60x improvement in one benchmark query.
\textbf{CPU vs. GPU: }Cost-models that accurately balance CPU and GPU utilization for query optimization will be a significant challenge. Some queries benefited by nearly two orders of magnitude, while other actually got slower when processing tasks were offloaded to a GPU.
\textbf{Managing Uncertainty and Approximation: }Unlike in relational databases, queries in a VDMS are approximate by nature. Different implementations may have different accuracy profiles and lead to query optimization problems that are not necessarily runtime driven.
One of our main conclusions is that \emph{query optimization and automated physical design are very much an open problem in the analysis of visual data.}


While it is natural to connect recent interest in visual analytics with prior work on multimedia databases (see survey~\cite{yoshitaka1999survey}), the recent instantiations of deep learning-based video analytics systems only loosely borrow from past architectural designs.
We argue that as the scope of visual analytics increases, scaling requires leveraging classical ideas from relational data management--as seen in the past with multimedia databases.
However, the tasks that we evaluate are significantly higher dimensional (images featurized by 1000 of dimensions) than ones considered in the past either in Geospatial databases or Multimedia databases.
Furthermore, the use cases have evolved where the metadata around the images is mostly generated by an automated deep learning pipeline rather than human provided.
Maintaining provenance to the raw data is crucial for debuging and merging different results. 
These differences aside, the core idea is the same: a relational database which holds structured metadata and image data with a relational data and query model. 
This way we can leverage the principles of design from relational database management systems and apply them to VDMS.











