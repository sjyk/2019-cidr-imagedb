\section{Experiments}
\textbf{TODO}

\subsection{Inferring depth maps}
One of the common downstream tasks in robotics is to estimate how far a given object is located from a moving robot. This requires an on-line analysis of the scene captured by a robot's camera and estimating the distances to the surrounding artifacts. This is a challenging problem that recently have been re-visited with the application of new models, such as deep neural networks. Novel approaches to the depth estimation task harness fully convolutional networks with embedded standard types of architecture, such as ResNet~\cite{resnet1, resnet2}, and additional layers for up-sampling the feature maps to the output depth maps, where each cell of the map represents an estimated distance from the camera to an object represented by the pixel. These new end-to-end models can be pre-trained on large RGB-D datasets, e.g., NYU Depth Dataset v2~\cite{nyuDepthDataset}. The RGB-D image has one additional channel \textit{D} representing the depth in comparison to standard images described in subsection~\ref{subsection:visualETL} that only store the three RGB channels. In our framework, we use a state of the art depth prediction model~\cite{depthPredictModel}. Such a pre-trained model on indoor and outdoor scenes can be readily applied to the inference on arbitrary images. We leverage the published code~\footnote{https://github.com/iro-cp/FCRN-DepthPrediction} and the pre-trained parameters of the model. We modified the provided implementation to load the model first, which should be done once during the system initialization, and then provide an API for an inference of a single RGB image or a batch of such images. The result is returned in the form of the depth map(s). The fully convolutional model~\cite{depthPredictModel} was originally implemented in TensorFlow~\cite{TensorFlow}. It  processes a single image within 55 to 78 ms, and in the batch mode (16 images per batch), it takes from 14 to 28 ms per image. This enables real-time depth prediction for images. Apart from single or multi-image depth estimation, such frameworks can be extended for using temporal information for enhanced and time-coherent depth prediction when multiple frames are available~\cite{videoDepthExtraction}.